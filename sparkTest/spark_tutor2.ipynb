{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** 教程 **\n",
    "https://www.cnblogs.com/muchen/p/6882276.html\n",
    "使用Spark对MovieLens的特征进行提取\n",
    "\n",
    "本章属于数据预处理环节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yang0/installer/spark-2.4.3-bin-hadoop2.7\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Jul 11 2019 14:32:02)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ.get('SPARK_HOME',None)\n",
    "print(spark_home)\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.10.4-src.zip'))\n",
    "\n",
    "exec(open(os.path.join(spark_home,'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**类别特征提取**\n",
    "在很多场景下，数据集的很多特征是类型变量，比如MovieLens里面的职业类型。这样的变量无法作为很多算法的输入，因为这类变量无法作用于样本间距离的计算。\n",
    "\n",
    "可参考的方法是 1 of k 编码，就是将某种类型的特征打平，将其转化为具有n列的向量。具体的做法是先为特征列创建字典，然后将各具体特征值映射到 1 of k 编码。\n",
    "\n",
    "下面以MoveiLens中的职业类型特征为例，演示特征值为programmer的特征提取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "程序员的1 of k编码为: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "user_data = sc.textFile(\"./ml-100k/u.user\")\n",
    "# 以' | '切分每列，返回新的用户RDD\n",
    "user_fields = user_data.map(lambda line: line.split(\"|\"))\n",
    "# 获取职业RDD并落地\n",
    "all_occupations = user_fields.map(lambda fields: fields[3]).distinct().collect()\n",
    "# 对各职业进行排序\n",
    "all_occupations.sort()\n",
    " \n",
    "# 构建字典\n",
    "idx = 0\n",
    "all_occupations_dict = {}\n",
    "for o in all_occupations:\n",
    "    all_occupations_dict[o] = idx\n",
    "    idx +=1\n",
    " \n",
    "# 生成并打印职业为程序员(programmer)的1 of k编码\n",
    "K = len(all_occupations_dict)\n",
    "binary_x = np.zeros(K)\n",
    "k_programmer = all_occupations_dict['programmer']\n",
    "binary_x[k_programmer] = 1\n",
    "print(\"程序员的1 of k编码为: %s\" % binary_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**派生特征提取**\n",
    " 并非所有的特征均可直接拿来学习。比如电影发行日期特征，它显然无法拿来进行学习。但正如上一节所做的一个工作，将它转化为电影年龄，这就可以在很多场景下进行学习了。\n",
    "\n",
    "再比如时间戳属性，可参考将他们转为为：早/中/晚这样的分类变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户id | 影片id | 评分值 | 时间戳(timestamp格式)\n",
      "196\t242\t3\t881250949\n",
      "[1 2 3 4 5 6 7 8 9]\n",
      "[23, 3, 15, 13, 13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['night', 'night', 'afternoon', 'lunch', 'lunch']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入数据集\n",
    "rating_data_raw = sc.textFile(\"./ml-100k/u.data\")\n",
    "print(\"用户id | 影片id | 评分值 | 时间戳(timestamp格式)\")\n",
    "print(rating_data_raw.first())\n",
    "\n",
    "# 获取评分RDD\n",
    "rating_data = rating_data_raw.map(lambda line: line.split(\"\\t\"))\n",
    "ratings = rating_data.map(lambda fields: int(fields[2]))\n",
    " \n",
    "# 函数: 将时间戳格式转换为datetime格式\n",
    "def extract_datetime(ts):\n",
    "    import datetime\n",
    "    return datetime.datetime.fromtimestamp(ts)\n",
    " \n",
    "# 获取小时RDD\n",
    "timestamps = rating_data.map(lambda fields: int(fields[3]))\n",
    "hour_of_day = timestamps.map(lambda ts: extract_datetime(ts).hour)\n",
    " \n",
    "# 函数: 将小时映射为分类变量并展示\n",
    "def assign_tod(hr):\n",
    "    times_of_day = {\n",
    "                'morning' : range(7, 12),\n",
    "                'lunch' : range(12, 14),\n",
    "                'afternoon' : range(14, 18),\n",
    "                'evening' : range(18, 23),\n",
    "                'night' : concatenate((range(23, 25),range(1,7)), 0) # 俩个数组合并，0是数组下标\n",
    "                }\n",
    "    for k, v in times_of_day.items():\n",
    "        if hr in v: \n",
    "            return k\n",
    " \n",
    "# 获取新的分类变量RDD\n",
    "a = concatenate((range(1, 7),range(7,10)), 0)\n",
    "print(a)\n",
    "print(hour_of_day.take(5))\n",
    "time_of_day = hour_of_day.map(lambda hr: assign_tod(hr))\n",
    "time_of_day.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**文本特征提取**\n",
    " 关于文本特征提取方法有很多，本文仅介绍一个简单而又经典的提取方法 - 词袋法。\n",
    "其基本步骤如下：\n",
    "\n",
    "1. 分词 - 将文本分割为由词组成的集合。可根据空格符，标点进行分割；\n",
    "2. 删除停用词 - the and 这类词无学习的价值意义，删除之；\n",
    "3. 提取词干 - 将各个词转化为其基本形式，如men -> man；\n",
    "4. 向量化 - 从根本上来说和1 of k相同。不过由于词往往很多，所以稀疏矩阵技术很重要；\n",
    "\n",
    "下面将MovieLens数据集中的影片标题进行特征提取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang0/.pyenv/versions/3.6.5/envs/py365/lib/python3.6/site-packages/scipy/sparse/_index.py:69: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "====\n",
      "['Toy', 'Story']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<1x2645 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2 stored elements in Compressed Sparse Column format>,\n",
       " <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1 stored elements in Compressed Sparse Column format>,\n",
       " <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2 stored elements in Compressed Sparse Column format>,\n",
       " <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2 stored elements in Compressed Sparse Column format>,\n",
       " <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1 stored elements in Compressed Sparse Column format>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入数据集\n",
    "movie_data = sc.textFile(\"./ml-100k/u.item\")\n",
    "\n",
    "# 1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "# 以' | '切分每列，返回影片RDD\n",
    "movie_fields = movie_data.map(lambda lines: lines.split(\"|\"))\n",
    " \n",
    "# 函数: 剔除掉标题中的(年份)部分\n",
    "def extract_title(raw):\n",
    "    import re\n",
    "    grps = re.search(\"\\((\\w+)\\)\", raw)\n",
    "    if grps:\n",
    "        return raw[:grps.start()].strip()\n",
    "    else:\n",
    "        return raw\n",
    " \n",
    "# 获取影片名RDD\n",
    "raw_titles = movie_fields.map(lambda fields: fields[1])\n",
    " \n",
    "# 剔除影片名中的(年份)\n",
    "movie_titles = raw_titles.map(lambda m: extract_title(m))\n",
    " \n",
    "# 由于仅仅是个展示的例子，简简单单用空格分割\n",
    "title_terms = movie_titles.map(lambda t: t.split(\" \"))\n",
    " \n",
    "# 搜集所有的词\n",
    "all_terms = title_terms.flatMap(lambda x: x).distinct().collect()\n",
    "\n",
    "# 创建字典\n",
    "idx = 0\n",
    "all_terms_dict = {}\n",
    "for term in all_terms:\n",
    "    all_terms_dict[term] = idx\n",
    "    idx +=1\n",
    "num_terms = len(all_terms_dict)\n",
    "\n",
    "from scipy import sparse as sp\n",
    "a = sp.csc_matrix((1, 3))\n",
    "a[0,2] = 1\n",
    "print(a)\n",
    "print(\"====\")\n",
    " \n",
    "# 函数: 采用稀疏向量格式保存编码后的特征并返回\n",
    "def create_vector(terms, term_dict):\n",
    "    x = sp.csc_matrix((1, num_terms))\n",
    "    for t in terms:\n",
    "        if t in term_dict:\n",
    "            idx = term_dict[t]\n",
    "            x[0, idx] = 1\n",
    "    return x\n",
    " \n",
    "# 将字典保存为广播数据格式类型。因为各个worker都要用\n",
    "all_terms_bcast = sc.broadcast(all_terms_dict)\n",
    "# 采用稀疏矩阵格式保存影片名特征\n",
    "\n",
    "print(title_terms.first())\n",
    "\n",
    "term_vectors = title_terms.map(lambda terms: create_vector(terms, all_terms_bcast.value))\n",
    "# 展示提取结果\n",
    "term_vectors.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化特征**\n",
    "\n",
    " 归一化最经典的做法就是所有特征值-最小值/特征区间。但对于一般特征的归一化网上很多介绍，请读者自行学习。本文仅对特征向量的归一化做介绍。\n",
    "\n",
    "一般来说，我们是先计算向量的二阶范数，然后让向量的所有元素去除以这个范数。\n",
    "\n",
    "下面演示对某随机向量进行归一化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量x:\n",
      "[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n",
      "向量x的2阶范数: 2.5908\n",
      "归一化后的向量x:\n",
      "[ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237\n",
      "  0.60954584  0.29621508 -0.1812081   0.20941776]\n",
      "归一化后向量x的2阶范数:\n",
      "1.0000\n"
     ]
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "np.random.seed(42)\n",
    "# 生成随机向量\n",
    "x = np.random.randn(10)\n",
    "# 产生二阶范数\n",
    "norm_x_2 = np.linalg.norm(x)\n",
    "# 归一化\n",
    "normalized_x = x / norm_x_2\n",
    " \n",
    "# 结果展示\n",
    "print(\"向量x:\\n%s\" % x)\n",
    "print(\"向量x的2阶范数: %2.4f\" % norm_x_2)\n",
    "print(\"归一化后的向量x:\\n%s\" % normalized_x)\n",
    "print(\"归一化后向量x的2阶范数:\\n%2.4f\" % np.linalg.norm(normalized_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么是范数？  https://blog.csdn.net/lz867422770/article/details/80013600\n",
    "\n",
    "我们知道距离的定义是一个宽泛的概念，只要满足非负、自反、三角不等式就可以称之为距离。范数是一种强化了的距离概念，它在定义上比距离多了一条数乘的运算法则。有时候为了便于理解，我们可以把范数当作距离来理解。\n",
    "\n",
    "在数学上，范数包括向量范数和矩阵范数，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。一种非严密的解释就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，不同的范数都可以来度量这个大小，就好比米和尺都可以来度量远近一样；对于矩阵范数，学过线性代数，我们知道，通过运算，可以将向量X变化为B，矩阵范数就是来度量这个变化大小的。\n",
    "\n",
    "\n",
    "二范数指矩阵A的2范数，就是A的转置共轭矩阵与矩阵A的积的最大特征根的平方根值，是指空间上两个向量矩阵的直线距离。类似于求棋盘上两点间的直线距离。\n",
    "\n",
    "不懂，需要补线性代数了\n",
    "\n",
    "https://www.jianshu.com/p/95a8f035c86c\n",
    "归一化：１）把数据变成(０，１)或者（1,1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。２）把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量x:\n",
      "[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n",
      "向量x的二阶范数: 2.5908\n",
      "被MLlib归一化后的向量x:\n",
      "[ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237\n",
      "  0.60954584  0.29621508 -0.1812081   0.20941776]\n",
      "被MLlib归一化后的向量x的二阶范数: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 导入Spark库中的正则化类\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "# 初始化正则化对象\n",
    "normalizer = Normalizer()\n",
    "# 创建测试向量(RDD)\n",
    "vector = sc.parallelize([x])\n",
    "# 对向量进行归一化并返回结果\n",
    "normalized_x_mllib = normalizer.transform(vector).first().toArray()\n",
    "  \n",
    "# 结果展示\n",
    "print(\"向量x:\\n%s\" % x)\n",
    "print(\"向量x的二阶范数: %2.4f\" % norm_x_2)\n",
    "print(\"被MLlib归一化后的向量x:\\n%s\" % normalized_x_mllib)\n",
    "print(\"被MLlib归一化后的向量x的二阶范数: %2.4f\" % np.linalg.norm(normalized_x_mllib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
